---
contributors: pitt500
---

Object Capture employs cutting-edge computer vision technologies to create a lifelike 3D model from a series of images taken at various angles. 
This technology was first introduced for macOS (more details in this [link](https://www.wwdcnotes.com/notes/wwdc21/10076/) from WWDC21) but now will be available in iOS 17 and above.

Apple is providing a sample app to demonstrate this capability. Follow this [link](https://developer.apple.com/documentation/realitykit/guided-capture-sample) to download the project.

# System Requirements
- iOS or iPadOS 17.
- A device with LiDAR scan.
- iPhone 12 Pro (or iPad Pro 2021) and later with LiDAR Sensor.

# Steps to scan objects using the demo app
- Open the app and point it at the object.
- You will see an automatic bounding box generated before starting capturing. You can adjust the edges to specify the scanning area.
- The app will guide you through the regions that need to scan more images.
- You can also see feedback from the app to help you capture the best quality shots.
- After finishing the first scanning, you can flip the object to capture the bottom (if needed).
- The app will require two more scan rounds, after finishing all, the app will start generating the 3D object model. You will have to wait a few minutes.
- Once the app completed the processing, it will provide a visualization of your new 3D model.

# Support more objects with LiDAR
- LiDAR Scanner has received improvements to scan and reconstruct low-texture objects, like this chair image:
  (Show Chair)
- Although low-texture objects are supported, some objects are still challenging to scan. Avoid objects that are:
  - Reflective
  - Transparent
  - Too-thin structures

# Flippable Objects
- Textured and rigid objects are great to be scanned from the bottom, but some others are not recommended, for example, objects with repetitive texture, deformable or textureless.
(Image to flippable objects)
- It's recommended to diffuse lights to minimize shadow and reflections over the object's surface.

# Non-flippable Objects
- It is recommended to scan them from 3 heights and use a textured background where they can stand out.
(Image to mug)

# Object Capture API
Object Capture API has two steps: 
1. Image Capture
2. Model reconstruction

## Image Capture API
- It has two parts:
  - A session from ObjectCaptureSession that allows you to object and control the flow of a state machine during the image capture.
  - A SwiftUI View that displays the camera feed and automatically adapts the UI elements based on the state of the session. 
## Model Reconstruction API
- A session starts at the initializing state.










If this is your first note, please make sure to check out the contributing guide https://github.com/WWDCNotes/Content/blob/main/CONTRIBUTING.md
